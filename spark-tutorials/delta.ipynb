{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/19 00:14:06 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.100.7 instead (on interface wlp3s0)\n",
      "23/11/19 00:14:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/radi/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/radi/.ivy2/cache\n",
      "The jars for the packages stored in: /home/radi/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-82889983-7042-4d2d-a465-aec0901500c2;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 281ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-82889983-7042-4d2d-a465-aec0901500c2\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/10ms)\n",
      "23/11/19 00:14:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/19 00:14:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from delta import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder.appName('Delta')\n",
    "    .master('local[*]')\n",
    "    .config('spark.dynamicAllocation.enabled', 'false')\n",
    "    .config('spark.jars.packages', 'io.delta:delta-core_2.12:2.4.0')\n",
    "    .config('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension')\n",
    "    .config('spark.sql.catalog.spark_catalog',\n",
    "            'org.apache.spark.sql.delta.catalog.DeltaCatalog')\n",
    "\n",
    "    .getOrCreate()            \n",
    ")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yello_taxi_schema = StructType([\n",
    "    StructField('VendorID', IntegerType(), True),\n",
    "    StructField('tpep_pickup_datetime', TimestampType(), True),\n",
    "    StructField('tpep_dropoff_datetime', TimestampType(), True),\n",
    "    StructField('passenger_count', DoubleType(), True),\n",
    "    StructField('trip_distance', DoubleType(), True),\n",
    "    StructField('RatecodeID', DoubleType(), True),\n",
    "    StructField('store_and_fwd_flag', StringType(), True),\n",
    "    StructField('PULocationID', IntegerType(), True),\n",
    "    StructField('DOLocationID', IntegerType(), True),\n",
    "    StructField('payment_type', IntegerType(), True),\n",
    "    StructField('fare_amount', DoubleType(), True),\n",
    "    StructField('extra', DoubleType(), True),\n",
    "    StructField('mta_tax', DoubleType(), True),\n",
    "    StructField('tip_amount', DoubleType(), True),\n",
    "    StructField('tolls_amount', DoubleType(), True),\n",
    "    StructField('improvement_surcharge', DoubleType(), True),\n",
    "    StructField('total_amount', DoubleType(), True),\n",
    "    StructField('congestion_surcharge', DoubleType(), True),\n",
    "    StructField('airport_fee', DoubleType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_taxi_df = (\n",
    "    spark\n",
    "        .read\n",
    "        .option('header', 'true')\n",
    "        .schema(yello_taxi_schema)\n",
    "        .csv('../data/taxi/YellowTaxis_202210.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|1       |2022-10-01 03:03:41 |2022-10-01 03:18:39  |1.0            |1.7          |1.0       |N                 |249         |107         |1           |9.5        |3.0  |0.5    |2.65      |0.0         |0.3                  |15.95       |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:14:30 |2022-10-01 03:19:48  |2.0            |0.72         |1.0       |N                 |151         |238         |2           |5.5        |0.5  |0.5    |0.0       |0.0         |0.3                  |9.3         |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:27:13 |2022-10-01 03:37:41  |1.0            |1.74         |1.0       |N                 |238         |166         |1           |9.0        |0.5  |0.5    |2.06      |0.0         |0.3                  |12.36       |0.0                 |0.0        |\n",
      "|1       |2022-10-01 03:32:53 |2022-10-01 03:38:55  |0.0            |1.3          |1.0       |N                 |142         |239         |1           |6.5        |3.0  |0.5    |2.05      |0.0         |0.3                  |12.35       |2.5                 |0.0        |\n",
      "|1       |2022-10-01 03:44:55 |2022-10-01 03:50:21  |0.0            |1.0          |1.0       |N                 |238         |166         |1           |6.0        |0.5  |0.5    |1.8       |0.0         |0.3                  |9.1         |0.0                 |0.0        |\n",
      "|1       |2022-10-01 03:22:52 |2022-10-01 03:52:14  |1.0            |6.8          |1.0       |Y                 |186         |41          |2           |25.5       |3.0  |0.5    |0.0       |0.0         |0.3                  |29.3        |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:33:19 |2022-10-01 03:44:51  |3.0            |1.88         |1.0       |N                 |162         |145         |2           |10.5       |0.5  |0.5    |0.0       |0.0         |0.3                  |14.3        |2.5                 |0.0        |\n",
      "|1       |2022-10-01 03:02:42 |2022-10-01 03:50:01  |1.0            |12.2         |1.0       |N                 |100         |22          |1           |41.0       |3.0  |0.5    |3.0       |0.0         |0.3                  |47.8        |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:06:35 |2022-10-01 03:24:38  |1.0            |7.79         |1.0       |N                 |138         |112         |1           |23.5       |0.5  |0.5    |4.96      |0.0         |0.3                  |31.01       |0.0                 |1.25       |\n",
      "|2       |2022-10-01 03:29:25 |2022-10-01 03:43:15  |1.0            |4.72         |1.0       |N                 |145         |75          |1           |14.5       |0.5  |0.5    |1.5       |0.0         |0.3                  |19.8        |2.5                 |0.0        |\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yellow_taxi_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS TaxiDB\n",
    "          \n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/19 00:14:54 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:14:57 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(yellow_taxi_df\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .partitionBy('VendorID')\n",
    "    .format('parquet')\n",
    "    .option('path', '/home/radi/Projects/DataLab/data/output/YelloTaxis.parquet')\n",
    "    .saveAsTable('TaxiDB.YellowTaxisParquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30/43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/19 00:16:16 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:16 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:24 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "(yellow_taxi_df\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .partitionBy('VendorID')\n",
    "    .format('delta')\n",
    "    .option('path', '/home/radi/Projects/DataLab/data/output/YelloTaxis.delta')\n",
    "    .saveAsTable('TaxiDB.YellowTaxis')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|2       |2022-10-03 18:17:20 |2022-10-03 18:32:06  |1.0            |1.83         |1.0       |N                 |230         |143         |1           |11.0       |0.0  |0.5    |2.86      |0.0         |0.3                  |17.16       |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:14:30 |2022-10-01 03:19:48  |2.0            |0.72         |1.0       |N                 |151         |238         |2           |5.5        |0.5  |0.5    |0.0       |0.0         |0.3                  |9.3         |2.5                 |0.0        |\n",
      "|2       |2022-10-03 18:25:49 |2022-10-03 18:48:02  |1.0            |1.99         |1.0       |N                 |162         |246         |1           |14.5       |0.0  |0.5    |3.56      |0.0         |0.3                  |21.36       |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:27:13 |2022-10-01 03:37:41  |1.0            |1.74         |1.0       |N                 |238         |166         |1           |9.0        |0.5  |0.5    |2.06      |0.0         |0.3                  |12.36       |0.0                 |0.0        |\n",
      "|2       |2022-10-03 18:57:06 |2022-10-03 19:05:05  |1.0            |2.17         |1.0       |N                 |246         |90          |1           |7.5        |0.0  |0.5    |2.16      |0.0         |0.3                  |12.96       |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:33:19 |2022-10-01 03:44:51  |3.0            |1.88         |1.0       |N                 |162         |145         |2           |10.5       |0.5  |0.5    |0.0       |0.0         |0.3                  |14.3        |2.5                 |0.0        |\n",
      "|2       |2022-10-03 18:20:55 |2022-10-03 18:24:20  |1.0            |0.66         |1.0       |N                 |233         |170         |2           |4.5        |0.0  |0.5    |0.0       |0.0         |0.3                  |7.8         |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:06:35 |2022-10-01 03:24:38  |1.0            |7.79         |1.0       |N                 |138         |112         |1           |23.5       |0.5  |0.5    |4.96      |0.0         |0.3                  |31.01       |0.0                 |1.25       |\n",
      "|2       |2022-10-03 18:27:04 |2022-10-03 18:43:37  |2.0            |2.21         |1.0       |N                 |137         |232         |1           |12.0       |0.0  |0.5    |5.0       |0.0         |0.3                  |20.3        |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:29:25 |2022-10-01 03:43:15  |1.0            |4.72         |1.0       |N                 |145         |75          |1           |14.5       |0.5  |0.5    |1.5       |0.0         |0.3                  |19.8        |2.5                 |0.0        |\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM TaxiDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation                        |operationParameters                                                                     |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                      |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|6      |2023-11-11 20:02:54.134|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |5          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|5      |2023-11-11 12:47:25.137|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |4          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|4      |2023-11-11 12:27:30.527|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |3          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|3      |2023-10-24 01:18:22.566|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |2          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|2      |2023-10-24 01:14:32.516|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |1          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|1      |2023-10-24 01:13:03.386|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |0          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|0      |2023-10-24 01:11:15.206|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |null       |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `TaxisDB`.`YellowTaxisNew` because it already exists.\nChoose a different name, drop or replace the existing object, or add the IF NOT EXISTS clause to tolerate pre-existing objects.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m spark\u001b[39m.\u001b[39;49msql(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mCREATE TABLE TaxisDB.YellowTaxisNew\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m(\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mVendorId    INT     COMMENT 'Vendor providing ride',\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mPickupTime  TIMESTAMP,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mDropTime    TIMESTAMP,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mPickupLocationId    INT NOT NULL,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mDropLocationID  INT,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mPassengerCount  DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mTripDistance    DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mRateCodeId  DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mStoreAndFwdFlag STRING,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mPaymentType INT,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mFareAmount  DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mExtra       DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mMtaTax      DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mTipAmount   DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mTollsAmount DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mImprovementSurcharge DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mTotalAmount DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mCongestionSurcharge DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mAirportFee DOUBLE\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m)    \u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mUSING DELTA\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mLOCATION \"/home/raddy/projects/DataLab/spark-tutorials/data/output/YelloTaxisNew.delta\"\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mPARTITIONED BY (VendorId)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mCOMMENT 'This table stores ride information for Yellow Taxis'\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     litArgs \u001b[39m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m (args \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m-> 1440\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsparkSession\u001b[39m.\u001b[39;49msql(sqlQuery, litArgs), \u001b[39mself\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(kwargs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `TaxisDB`.`YellowTaxisNew` because it already exists.\nChoose a different name, drop or replace the existing object, or add the IF NOT EXISTS clause to tolerate pre-existing objects."
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "CREATE TABLE TaxisDB.YellowTaxisNew\n",
    "(\n",
    "VendorId    INT     COMMENT 'Vendor providing ride',\n",
    "\n",
    "PickupTime  TIMESTAMP,\n",
    "DropTime    TIMESTAMP,\n",
    "\n",
    "PickupLocationId    INT NOT NULL,\n",
    "DropLocationID  INT,\n",
    "\n",
    "PassengerCount  DOUBLE,\n",
    "TripDistance    DOUBLE,\n",
    "\n",
    "RateCodeId  DOUBLE,\n",
    "StoreAndFwdFlag STRING,\n",
    "PaymentType INT,\n",
    "\n",
    "FareAmount  DOUBLE,\n",
    "Extra       DOUBLE,\n",
    "MtaTax      DOUBLE,\n",
    "TipAmount   DOUBLE,\n",
    "TollsAmount DOUBLE,\n",
    "ImprovementSurcharge DOUBLE,\n",
    "TotalAmount DOUBLE,\n",
    "CongestionSurcharge DOUBLE,\n",
    "AirportFee DOUBLE\n",
    "\n",
    ")    \n",
    "\n",
    "USING DELTA\n",
    "\n",
    "LOCATION \"/home/raddy/projects/DataLab/spark-tutorials/data/output/YelloTaxisNew.delta\"\n",
    "\n",
    "PARTITIONED BY (VendorId)\n",
    "\n",
    "COMMENT 'This table stores ride information for Yellow Taxis'\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------------------------------------+---------------------+\n",
      "|col_name                    |data_type                                                                        |comment              |\n",
      "+----------------------------+---------------------------------------------------------------------------------+---------------------+\n",
      "|VendorId                    |int                                                                              |Vendor providing ride|\n",
      "|PickupTime                  |timestamp                                                                        |null                 |\n",
      "|DropTime                    |timestamp                                                                        |null                 |\n",
      "|PickupLocationId            |int                                                                              |null                 |\n",
      "|DropLocationID              |int                                                                              |null                 |\n",
      "|PassengerCount              |double                                                                           |null                 |\n",
      "|TripDistance                |double                                                                           |null                 |\n",
      "|RateCodeId                  |double                                                                           |null                 |\n",
      "|StoreAndFwdFlag             |string                                                                           |null                 |\n",
      "|PaymentType                 |int                                                                              |null                 |\n",
      "|FareAmount                  |double                                                                           |null                 |\n",
      "|Extra                       |double                                                                           |null                 |\n",
      "|MtaTax                      |double                                                                           |null                 |\n",
      "|TipAmount                   |double                                                                           |null                 |\n",
      "|TollsAmount                 |double                                                                           |null                 |\n",
      "|ImprovementSurcharge        |double                                                                           |null                 |\n",
      "|TotalAmount                 |double                                                                           |null                 |\n",
      "|CongestionSurcharge         |double                                                                           |null                 |\n",
      "|AirportFee                  |double                                                                           |null                 |\n",
      "|# Partition Information     |                                                                                 |                     |\n",
      "|# col_name                  |data_type                                                                        |comment              |\n",
      "|VendorId                    |int                                                                              |Vendor providing ride|\n",
      "|                            |                                                                                 |                     |\n",
      "|# Detailed Table Information|                                                                                 |                     |\n",
      "|Name                        |spark_catalog.taxisdb.yellowtaxisnew                                             |                     |\n",
      "|Type                        |EXTERNAL                                                                         |                     |\n",
      "|Comment                     |This table stores ride information for Yellow Taxis                              |                     |\n",
      "|Location                    |file:/home/raddy/projects/DataLab/spark-tutorials/data/output/YelloTaxisNew.delta|                     |\n",
      "|Provider                    |delta                                                                            |                     |\n",
      "|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2]                              |                     |\n",
      "+----------------------------+---------------------------------------------------------------------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "DESCRIBE TABLE EXTENDED TaxisDB.YellowTaxisNew\n",
    "\"\"\"\n",
    ").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+------------+---------------+\n",
      "|input_file_name()|VendorID|PULocationID|passenger_count|\n",
      "+-----------------+--------+------------+---------------+\n",
      "+-----------------+--------+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT INPUT_FILE_NAME()\n",
    "          ,VendorID\n",
    "          ,PULocationID\n",
    "          ,passenger_count\n",
    "\n",
    "          FROM TaxisDB.YellowTaxis\n",
    "          WHERE VendorId=3\n",
    "\n",
    "          \"\"\").show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
