{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/07/18 20:18:35 WARN Utils: Your hostname, mac-radi.local resolves to a loopback address: 127.0.0.1; using 192.168.100.157 instead (on interface en0)\n",
      "25/07/18 20:18:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/radi/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/radi/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/radi/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-baf2700a-b489-45c2-8f67-856ea5d521c9;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 89ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-baf2700a-b489-45c2-8f67-856ea5d521c9\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/2ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/07/18 20:18:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from delta import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder.appName('Delta')\n",
    "    .master('local[*]')\n",
    "    .config('spark.dynamicAllocation.enabled', 'false')\n",
    "    .config('spark.jars.packages', 'io.delta:delta-core_2.12:2.4.0')\n",
    "    .config('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension')\n",
    "    .config('spark.sql.catalog.spark_catalog',\n",
    "            'org.apache.spark.sql.delta.catalog.DeltaCatalog')\n",
    "\n",
    "    .getOrCreate()            \n",
    ")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yello_taxi_schema = StructType([\n",
    "    StructField('VendorID', IntegerType(), True),\n",
    "    StructField('tpep_pickup_datetime', TimestampType(), True),\n",
    "    StructField('tpep_dropoff_datetime', TimestampType(), True),\n",
    "    StructField('passenger_count', DoubleType(), True),\n",
    "    StructField('trip_distance', DoubleType(), True),\n",
    "    StructField('RatecodeID', DoubleType(), True),\n",
    "    StructField('store_and_fwd_flag', StringType(), True),\n",
    "    StructField('PULocationID', IntegerType(), True),\n",
    "    StructField('DOLocationID', IntegerType(), True),\n",
    "    StructField('payment_type', IntegerType(), True),\n",
    "    StructField('fare_amount', DoubleType(), True),\n",
    "    StructField('extra', DoubleType(), True),\n",
    "    StructField('mta_tax', DoubleType(), True),\n",
    "    StructField('tip_amount', DoubleType(), True),\n",
    "    StructField('tolls_amount', DoubleType(), True),\n",
    "    StructField('improvement_surcharge', DoubleType(), True),\n",
    "    StructField('total_amount', DoubleType(), True),\n",
    "    StructField('congestion_surcharge', DoubleType(), True),\n",
    "    StructField('airport_fee', DoubleType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_taxi_df = (\n",
    "    spark\n",
    "        .read\n",
    "        .option('header', 'true')\n",
    "        .schema(yello_taxi_schema)\n",
    "        .csv('/Users/radi/Projects/DataLab/data/taxi/YellowTaxis_202210.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "FileScan csv [VendorID#0,tpep_pickup_datetime#1,tpep_dropoff_datetime#2,passenger_count#3,trip_distance#4,RatecodeID#5,store_and_fwd_flag#6,PULocationID#7,DOLocationID#8,payment_type#9,fare_amount#10,extra#11,mta_tax#12,tip_amount#13,tolls_amount#14,improvement_surcharge#15,total_amount#16,congestion_surcharge#17,airport_fee#18] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/radi/Projects/DataLab/data/taxi/YellowTaxis_202210.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<VendorID:int,tpep_pickup_datetime:timestamp,tpep_dropoff_datetime:timestamp,passenger_coun...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yellow_taxi_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__name__\n",
      "__doc__\n",
      "__package__\n",
      "__loader__\n",
      "__spec__\n",
      "__builtin__\n",
      "__builtins__\n",
      "_ih\n",
      "_oh\n",
      "_dh\n",
      "In\n",
      "Out\n",
      "get_ipython\n",
      "exit\n",
      "quit\n",
      "open\n",
      "_\n",
      "__\n",
      "___\n",
      "__vsc_ipynb_file__\n",
      "_i\n",
      "_ii\n",
      "_iii\n",
      "_i1\n",
      "SparkSession\n",
      "DataType\n",
      "NullType\n",
      "StringType\n",
      "BinaryType\n",
      "BooleanType\n",
      "DateType\n",
      "TimestampType\n",
      "DecimalType\n",
      "DoubleType\n",
      "FloatType\n",
      "ByteType\n",
      "IntegerType\n",
      "LongType\n",
      "DayTimeIntervalType\n",
      "Row\n",
      "ShortType\n",
      "ArrayType\n",
      "MapType\n",
      "StructField\n",
      "StructType\n",
      "inspect\n",
      "sys\n",
      "functools\n",
      "warnings\n",
      "Any\n",
      "cast\n",
      "Callable\n",
      "Dict\n",
      "List\n",
      "Iterable\n",
      "overload\n",
      "Optional\n",
      "Tuple\n",
      "TYPE_CHECKING\n",
      "Union\n",
      "ValuesView\n",
      "since\n",
      "SparkContext\n",
      "PythonEvalType\n",
      "Column\n",
      "DataFrame\n",
      "UserDefinedFunction\n",
      "pandas_udf\n",
      "PandasUDFType\n",
      "to_str\n",
      "lit\n",
      "col\n",
      "column\n",
      "asc\n",
      "desc\n",
      "sqrt\n",
      "abs\n",
      "max\n",
      "min\n",
      "max_by\n",
      "min_by\n",
      "count\n",
      "sum\n",
      "avg\n",
      "mean\n",
      "sumDistinct\n",
      "sum_distinct\n",
      "product\n",
      "acos\n",
      "acosh\n",
      "asin\n",
      "asinh\n",
      "atan\n",
      "atanh\n",
      "cbrt\n",
      "ceil\n",
      "cos\n",
      "cosh\n",
      "cot\n",
      "csc\n",
      "exp\n",
      "expm1\n",
      "floor\n",
      "log\n",
      "log10\n",
      "log1p\n",
      "rint\n",
      "sec\n",
      "signum\n",
      "sin\n",
      "sinh\n",
      "tan\n",
      "tanh\n",
      "toDegrees\n",
      "toRadians\n",
      "bitwiseNOT\n",
      "bitwise_not\n",
      "asc_nulls_first\n",
      "asc_nulls_last\n",
      "desc_nulls_first\n",
      "desc_nulls_last\n",
      "stddev\n",
      "stddev_samp\n",
      "stddev_pop\n",
      "variance\n",
      "var_samp\n",
      "var_pop\n",
      "skewness\n",
      "kurtosis\n",
      "collect_list\n",
      "collect_set\n",
      "degrees\n",
      "radians\n",
      "atan2\n",
      "hypot\n",
      "pow\n",
      "row_number\n",
      "dense_rank\n",
      "rank\n",
      "cume_dist\n",
      "percent_rank\n",
      "approxCountDistinct\n",
      "approx_count_distinct\n",
      "broadcast\n",
      "coalesce\n",
      "corr\n",
      "covar_pop\n",
      "covar_samp\n",
      "countDistinct\n",
      "count_distinct\n",
      "first\n",
      "grouping\n",
      "grouping_id\n",
      "input_file_name\n",
      "isnan\n",
      "isnull\n",
      "last\n",
      "monotonically_increasing_id\n",
      "nanvl\n",
      "percentile_approx\n",
      "rand\n",
      "randn\n",
      "round\n",
      "bround\n",
      "shiftLeft\n",
      "shiftleft\n",
      "shiftRight\n",
      "shiftright\n",
      "shiftRightUnsigned\n",
      "shiftrightunsigned\n",
      "spark_partition_id\n",
      "expr\n",
      "struct\n",
      "greatest\n",
      "least\n",
      "when\n",
      "log2\n",
      "conv\n",
      "factorial\n",
      "lag\n",
      "lead\n",
      "nth_value\n",
      "ntile\n",
      "current_date\n",
      "current_timestamp\n",
      "date_format\n",
      "year\n",
      "quarter\n",
      "month\n",
      "dayofweek\n",
      "dayofmonth\n",
      "dayofyear\n",
      "hour\n",
      "minute\n",
      "second\n",
      "weekofyear\n",
      "make_date\n",
      "date_add\n",
      "date_sub\n",
      "datediff\n",
      "add_months\n",
      "months_between\n",
      "to_date\n",
      "to_timestamp\n",
      "trunc\n",
      "date_trunc\n",
      "next_day\n",
      "last_day\n",
      "from_unixtime\n",
      "unix_timestamp\n",
      "from_utc_timestamp\n",
      "to_utc_timestamp\n",
      "timestamp_seconds\n",
      "window\n",
      "session_window\n",
      "crc32\n",
      "md5\n",
      "sha1\n",
      "sha2\n",
      "hash\n",
      "xxhash64\n",
      "assert_true\n",
      "raise_error\n",
      "upper\n",
      "lower\n",
      "ascii\n",
      "base64\n",
      "unbase64\n",
      "ltrim\n",
      "rtrim\n",
      "trim\n",
      "concat_ws\n",
      "decode\n",
      "encode\n",
      "format_number\n",
      "format_string\n",
      "instr\n",
      "overlay\n",
      "sentences\n",
      "substring\n",
      "substring_index\n",
      "levenshtein\n",
      "locate\n",
      "lpad\n",
      "rpad\n",
      "repeat\n",
      "split\n",
      "regexp_extract\n",
      "regexp_replace\n",
      "initcap\n",
      "soundex\n",
      "bin\n",
      "hex\n",
      "unhex\n",
      "length\n",
      "octet_length\n",
      "bit_length\n",
      "translate\n",
      "create_map\n",
      "map_from_arrays\n",
      "array\n",
      "array_contains\n",
      "arrays_overlap\n",
      "slice\n",
      "array_join\n",
      "concat\n",
      "array_position\n",
      "element_at\n",
      "array_remove\n",
      "array_distinct\n",
      "array_intersect\n",
      "array_union\n",
      "array_except\n",
      "explode\n",
      "posexplode\n",
      "explode_outer\n",
      "posexplode_outer\n",
      "get_json_object\n",
      "json_tuple\n",
      "from_json\n",
      "to_json\n",
      "schema_of_json\n",
      "schema_of_csv\n",
      "to_csv\n",
      "size\n",
      "array_min\n",
      "array_max\n",
      "sort_array\n",
      "array_sort\n",
      "shuffle\n",
      "reverse\n",
      "flatten\n",
      "map_keys\n",
      "map_values\n",
      "map_entries\n",
      "map_from_entries\n",
      "array_repeat\n",
      "arrays_zip\n",
      "map_concat\n",
      "sequence\n",
      "from_csv\n",
      "transform\n",
      "exists\n",
      "forall\n",
      "filter\n",
      "aggregate\n",
      "zip_with\n",
      "transform_keys\n",
      "transform_values\n",
      "map_filter\n",
      "map_zip_with\n",
      "years\n",
      "months\n",
      "days\n",
      "hours\n",
      "bucket\n",
      "udf\n",
      "DeltaTable\n",
      "configure_spark_with_delta_pip\n",
      "spark\n",
      "sc\n",
      "_i2\n",
      "yello_taxi_schema\n",
      "_i3\n",
      "_i4\n",
      "yellow_taxi_df\n",
      "_i5\n",
      "_i6\n",
      "_6\n",
      "_i7\n",
      "i\n",
      "_i8\n"
     ]
    }
   ],
   "source": [
    "for i in globals().keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notifyme(f):\n",
    "    def logged(*args, **kwargs):\n",
    "        print(f.__name__, ' called with', args, 'and', kwargs)\n",
    "        return f(*args, **kwargs)\n",
    "    return logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square  called with (25,) and {}\n"
     ]
    }
   ],
   "source": [
    "@notifyme\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "\n",
    "res = square(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(x):\n",
    " def increment(y):\n",
    "    return x + y\n",
    " return increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = start(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|1       |2022-10-01 03:03:41 |2022-10-01 03:18:39  |1.0            |1.7          |1.0       |N                 |249         |107         |1           |9.5        |3.0  |0.5    |2.65      |0.0         |0.3                  |15.95       |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:14:30 |2022-10-01 03:19:48  |2.0            |0.72         |1.0       |N                 |151         |238         |2           |5.5        |0.5  |0.5    |0.0       |0.0         |0.3                  |9.3         |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:27:13 |2022-10-01 03:37:41  |1.0            |1.74         |1.0       |N                 |238         |166         |1           |9.0        |0.5  |0.5    |2.06      |0.0         |0.3                  |12.36       |0.0                 |0.0        |\n",
      "|1       |2022-10-01 03:32:53 |2022-10-01 03:38:55  |0.0            |1.3          |1.0       |N                 |142         |239         |1           |6.5        |3.0  |0.5    |2.05      |0.0         |0.3                  |12.35       |2.5                 |0.0        |\n",
      "|1       |2022-10-01 03:44:55 |2022-10-01 03:50:21  |0.0            |1.0          |1.0       |N                 |238         |166         |1           |6.0        |0.5  |0.5    |1.8       |0.0         |0.3                  |9.1         |0.0                 |0.0        |\n",
      "|1       |2022-10-01 03:22:52 |2022-10-01 03:52:14  |1.0            |6.8          |1.0       |Y                 |186         |41          |2           |25.5       |3.0  |0.5    |0.0       |0.0         |0.3                  |29.3        |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:33:19 |2022-10-01 03:44:51  |3.0            |1.88         |1.0       |N                 |162         |145         |2           |10.5       |0.5  |0.5    |0.0       |0.0         |0.3                  |14.3        |2.5                 |0.0        |\n",
      "|1       |2022-10-01 03:02:42 |2022-10-01 03:50:01  |1.0            |12.2         |1.0       |N                 |100         |22          |1           |41.0       |3.0  |0.5    |3.0       |0.0         |0.3                  |47.8        |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:06:35 |2022-10-01 03:24:38  |1.0            |7.79         |1.0       |N                 |138         |112         |1           |23.5       |0.5  |0.5    |4.96      |0.0         |0.3                  |31.01       |0.0                 |1.25       |\n",
      "|2       |2022-10-01 03:29:25 |2022-10-01 03:43:15  |1.0            |4.72         |1.0       |N                 |145         |75          |1           |14.5       |0.5  |0.5    |1.5       |0.0         |0.3                  |19.8        |2.5                 |0.0        |\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yellow_taxi_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS TaxiDB\n",
    "          \n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/19 00:14:54 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:14:57 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(yellow_taxi_df\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .partitionBy('VendorID')\n",
    "    .format('parquet')\n",
    "    .option('path', '/home/radi/Projects/DataLab/data/output/YelloTaxis.parquet')\n",
    "    .saveAsTable('TaxiDB.YellowTaxisParquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30/43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/19 00:16:16 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:16 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/11/19 00:16:24 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "(yellow_taxi_df\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .partitionBy('VendorID')\n",
    "    .format('delta')\n",
    "    .option('path', '/home/radi/Projects/DataLab/data/output/YelloTaxis.delta')\n",
    "    .saveAsTable('TaxiDB.YellowTaxis')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|2       |2022-10-03 18:17:20 |2022-10-03 18:32:06  |1.0            |1.83         |1.0       |N                 |230         |143         |1           |11.0       |0.0  |0.5    |2.86      |0.0         |0.3                  |17.16       |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:14:30 |2022-10-01 03:19:48  |2.0            |0.72         |1.0       |N                 |151         |238         |2           |5.5        |0.5  |0.5    |0.0       |0.0         |0.3                  |9.3         |2.5                 |0.0        |\n",
      "|2       |2022-10-03 18:25:49 |2022-10-03 18:48:02  |1.0            |1.99         |1.0       |N                 |162         |246         |1           |14.5       |0.0  |0.5    |3.56      |0.0         |0.3                  |21.36       |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:27:13 |2022-10-01 03:37:41  |1.0            |1.74         |1.0       |N                 |238         |166         |1           |9.0        |0.5  |0.5    |2.06      |0.0         |0.3                  |12.36       |0.0                 |0.0        |\n",
      "|2       |2022-10-03 18:57:06 |2022-10-03 19:05:05  |1.0            |2.17         |1.0       |N                 |246         |90          |1           |7.5        |0.0  |0.5    |2.16      |0.0         |0.3                  |12.96       |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:33:19 |2022-10-01 03:44:51  |3.0            |1.88         |1.0       |N                 |162         |145         |2           |10.5       |0.5  |0.5    |0.0       |0.0         |0.3                  |14.3        |2.5                 |0.0        |\n",
      "|2       |2022-10-03 18:20:55 |2022-10-03 18:24:20  |1.0            |0.66         |1.0       |N                 |233         |170         |2           |4.5        |0.0  |0.5    |0.0       |0.0         |0.3                  |7.8         |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:06:35 |2022-10-01 03:24:38  |1.0            |7.79         |1.0       |N                 |138         |112         |1           |23.5       |0.5  |0.5    |4.96      |0.0         |0.3                  |31.01       |0.0                 |1.25       |\n",
      "|2       |2022-10-03 18:27:04 |2022-10-03 18:43:37  |2.0            |2.21         |1.0       |N                 |137         |232         |1           |12.0       |0.0  |0.5    |5.0       |0.0         |0.3                  |20.3        |2.5                 |0.0        |\n",
      "|2       |2022-10-01 03:29:25 |2022-10-01 03:43:15  |1.0            |4.72         |1.0       |N                 |145         |75          |1           |14.5       |0.5  |0.5    |1.5       |0.0         |0.3                  |19.8        |2.5                 |0.0        |\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM TaxiDB.YellowTaxis\n",
    "\n",
    "\"\"\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation                        |operationParameters                                                                     |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                      |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|6      |2023-11-11 20:02:54.134|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |5          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|5      |2023-11-11 12:47:25.137|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |4          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|4      |2023-11-11 12:27:30.527|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |3          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|3      |2023-10-24 01:18:22.566|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |2          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|2      |2023-10-24 01:14:32.516|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |1          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|1      |2023-10-24 01:13:03.386|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |0          |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "|0      |2023-10-24 01:11:15.206|null  |null    |CREATE OR REPLACE TABLE AS SELECT|{isManaged -> false, description -> null, partitionBy -> [\"VendorID\"], properties -> {}}|null|null    |null     |null       |Serializable  |false        |{numFiles -> 17, numOutputRows -> 3675412, numOutputBytes -> 81520769}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESCRIBE HISTORY TaxisDB.YellowTaxis\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `TaxisDB`.`YellowTaxisNew` because it already exists.\nChoose a different name, drop or replace the existing object, or add the IF NOT EXISTS clause to tolerate pre-existing objects.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m spark\u001b[39m.\u001b[39;49msql(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mCREATE TABLE TaxisDB.YellowTaxisNew\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m(\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mVendorId    INT     COMMENT 'Vendor providing ride',\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mPickupTime  TIMESTAMP,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mDropTime    TIMESTAMP,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mPickupLocationId    INT NOT NULL,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mDropLocationID  INT,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mPassengerCount  DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mTripDistance    DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mRateCodeId  DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mStoreAndFwdFlag STRING,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mPaymentType INT,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mFareAmount  DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mExtra       DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mMtaTax      DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mTipAmount   DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mTollsAmount DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mImprovementSurcharge DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mTotalAmount DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mCongestionSurcharge DOUBLE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mAirportFee DOUBLE\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m)    \u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mUSING DELTA\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mLOCATION \"/home/raddy/projects/DataLab/spark-tutorials/data/output/YelloTaxisNew.delta\"\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mPARTITIONED BY (VendorId)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mCOMMENT 'This table stores ride information for Yellow Taxis'\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/raddy/projects/DataLab/spark-tutorials/delta.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     litArgs \u001b[39m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m (args \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m-> 1440\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsparkSession\u001b[39m.\u001b[39;49msql(sqlQuery, litArgs), \u001b[39mself\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(kwargs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `TaxisDB`.`YellowTaxisNew` because it already exists.\nChoose a different name, drop or replace the existing object, or add the IF NOT EXISTS clause to tolerate pre-existing objects."
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "CREATE TABLE TaxisDB.YellowTaxisNew\n",
    "(\n",
    "VendorId    INT     COMMENT 'Vendor providing ride',\n",
    "\n",
    "PickupTime  TIMESTAMP,\n",
    "DropTime    TIMESTAMP,\n",
    "\n",
    "PickupLocationId    INT NOT NULL,\n",
    "DropLocationID  INT,\n",
    "\n",
    "PassengerCount  DOUBLE,\n",
    "TripDistance    DOUBLE,\n",
    "\n",
    "RateCodeId  DOUBLE,\n",
    "StoreAndFwdFlag STRING,\n",
    "PaymentType INT,\n",
    "\n",
    "FareAmount  DOUBLE,\n",
    "Extra       DOUBLE,\n",
    "MtaTax      DOUBLE,\n",
    "TipAmount   DOUBLE,\n",
    "TollsAmount DOUBLE,\n",
    "ImprovementSurcharge DOUBLE,\n",
    "TotalAmount DOUBLE,\n",
    "CongestionSurcharge DOUBLE,\n",
    "AirportFee DOUBLE\n",
    "\n",
    ")    \n",
    "\n",
    "USING DELTA\n",
    "\n",
    "LOCATION \"/home/raddy/projects/DataLab/spark-tutorials/data/output/YelloTaxisNew.delta\"\n",
    "\n",
    "PARTITIONED BY (VendorId)\n",
    "\n",
    "COMMENT 'This table stores ride information for Yellow Taxis'\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------------------------------------+---------------------+\n",
      "|col_name                    |data_type                                                                        |comment              |\n",
      "+----------------------------+---------------------------------------------------------------------------------+---------------------+\n",
      "|VendorId                    |int                                                                              |Vendor providing ride|\n",
      "|PickupTime                  |timestamp                                                                        |null                 |\n",
      "|DropTime                    |timestamp                                                                        |null                 |\n",
      "|PickupLocationId            |int                                                                              |null                 |\n",
      "|DropLocationID              |int                                                                              |null                 |\n",
      "|PassengerCount              |double                                                                           |null                 |\n",
      "|TripDistance                |double                                                                           |null                 |\n",
      "|RateCodeId                  |double                                                                           |null                 |\n",
      "|StoreAndFwdFlag             |string                                                                           |null                 |\n",
      "|PaymentType                 |int                                                                              |null                 |\n",
      "|FareAmount                  |double                                                                           |null                 |\n",
      "|Extra                       |double                                                                           |null                 |\n",
      "|MtaTax                      |double                                                                           |null                 |\n",
      "|TipAmount                   |double                                                                           |null                 |\n",
      "|TollsAmount                 |double                                                                           |null                 |\n",
      "|ImprovementSurcharge        |double                                                                           |null                 |\n",
      "|TotalAmount                 |double                                                                           |null                 |\n",
      "|CongestionSurcharge         |double                                                                           |null                 |\n",
      "|AirportFee                  |double                                                                           |null                 |\n",
      "|# Partition Information     |                                                                                 |                     |\n",
      "|# col_name                  |data_type                                                                        |comment              |\n",
      "|VendorId                    |int                                                                              |Vendor providing ride|\n",
      "|                            |                                                                                 |                     |\n",
      "|# Detailed Table Information|                                                                                 |                     |\n",
      "|Name                        |spark_catalog.taxisdb.yellowtaxisnew                                             |                     |\n",
      "|Type                        |EXTERNAL                                                                         |                     |\n",
      "|Comment                     |This table stores ride information for Yellow Taxis                              |                     |\n",
      "|Location                    |file:/home/raddy/projects/DataLab/spark-tutorials/data/output/YelloTaxisNew.delta|                     |\n",
      "|Provider                    |delta                                                                            |                     |\n",
      "|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2]                              |                     |\n",
      "+----------------------------+---------------------------------------------------------------------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "DESCRIBE TABLE EXTENDED TaxisDB.YellowTaxisNew\n",
    "\"\"\"\n",
    ").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+------------+---------------+\n",
      "|input_file_name()|VendorID|PULocationID|passenger_count|\n",
      "+-----------------+--------+------------+---------------+\n",
      "+-----------------+--------+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT INPUT_FILE_NAME()\n",
    "          ,VendorID\n",
    "          ,PULocationID\n",
    "          ,passenger_count\n",
    "\n",
    "          FROM TaxisDB.YellowTaxis\n",
    "          WHERE VendorId=3\n",
    "\n",
    "          \"\"\").show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
